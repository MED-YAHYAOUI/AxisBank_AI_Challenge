{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Installing PyTorch and Pillow == 0.4","metadata":{"id":"3DO8GbvHCTFe"}},{"cell_type":"code","source":"from os import path\n#from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n#platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n\n#accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n\n!pip install -q http://download.pytorch.org/whl/cu91/torch-0.4.0-cp36-cp36m-linux_x86_64.whl torchvision\nimport torch\nprint(torch.__version__)\nprint(torch.cuda.is_available())","metadata":{"id":"a-aWTgsoqPMY","outputId":"1c3947e6-7989-4764-d51a-d631c9f7eb40","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nprint(torch.__version__)\nprint(torch.cuda.is_available())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%conda install Pillow","metadata":{"id":"dgvaG5wBxh5r","outputId":"ddb6763c-fb11-4be5-c71e-d4f29f8ce0a9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Imports\nAll the imports are defined here\n","metadata":{"id":"_KDVGZSzwL8C"}},{"cell_type":"code","source":"%matplotlib inline\nimport os\nimport torchvision\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader,Dataset\nimport matplotlib.pyplot as plt\nimport torchvision.utils\nimport numpy as np\nimport random\nfrom PIL import Image\nimport torch\nfrom torch.autograd import Variable\nimport PIL.ImageOps    \nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F","metadata":{"id":"DoZYfkp1s3g0","execution":{"iopub.status.busy":"2022-04-06T13:02:04.274487Z","iopub.execute_input":"2022-04-06T13:02:04.275108Z","iopub.status.idle":"2022-04-06T13:02:05.802061Z","shell.execute_reply.started":"2022-04-06T13:02:04.275063Z","shell.execute_reply":"2022-04-06T13:02:05.801328Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/MED-YAHYAOUI/AxisBank_AI_Challenge.git","metadata":{"execution":{"iopub.status.busy":"2022-04-06T13:34:07.085511Z","iopub.execute_input":"2022-04-06T13:34:07.086284Z","iopub.status.idle":"2022-04-06T13:34:13.818896Z","shell.execute_reply.started":"2022-04-06T13:34:07.086245Z","shell.execute_reply":"2022-04-06T13:34:13.818087Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"Vv3mWNVfuNy7","outputId":"71a27946-d16b-4618-c1f6-b799a1c452ba"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls './AxisBank_AI_Challenge/Forged_Signature_Verification/processed_dataset'","metadata":{"id":"xATopGlGvTM7","outputId":"6b19e1d2-627e-4b40-c880-e88078f25f32","execution":{"iopub.status.busy":"2022-04-06T13:34:17.033851Z","iopub.execute_input":"2022-04-06T13:34:17.034674Z","iopub.status.idle":"2022-04-06T13:34:17.746981Z","shell.execute_reply.started":"2022-04-06T13:34:17.034579Z","shell.execute_reply":"2022-04-06T13:34:17.746115Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":"## Helper functions\nSet of helper functions\n\n","metadata":{"id":"zaMupE2kv6DX"}},{"cell_type":"code","source":"def imshow(img,text=None,should_save=False):\n    npimg = img.numpy()\n    plt.axis(\"off\")\n    if text:\n        plt.text(75, 8, text, style='italic',fontweight='bold',\n            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()    \n\ndef show_plot(iteration,loss):\n    plt.plot(iteration,loss)\n    plt.show()","metadata":{"id":"9XhfF_Z2v-Ey","execution":{"iopub.status.busy":"2022-04-06T13:02:20.977703Z","iopub.execute_input":"2022-04-06T13:02:20.977979Z","iopub.status.idle":"2022-04-06T13:02:20.985224Z","shell.execute_reply.started":"2022-04-06T13:02:20.977951Z","shell.execute_reply":"2022-04-06T13:02:20.984493Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Configuration Class\nA simple class to manage configuration\n","metadata":{"id":"qdJqNGCdwDKK"}},{"cell_type":"code","source":"class Config():\n    training_dir = \"./AxisBank_AI_Challenge/Forged_Signature_Verification/processed_dataset/training/\"\n    testing_dir = \"./AxisBank_AI_Challenge/Forged_Signature_Verification/processed_dataset/testing/\"\n    train_batch_size = 64\n    train_number_epochs = 500","metadata":{"id":"L1e-CgF5wBZT","execution":{"iopub.status.busy":"2022-04-06T13:34:20.874080Z","iopub.execute_input":"2022-04-06T13:34:20.874372Z","iopub.status.idle":"2022-04-06T13:34:20.879552Z","shell.execute_reply.started":"2022-04-06T13:34:20.874343Z","shell.execute_reply":"2022-04-06T13:34:20.878654Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":"#### Class Mapping","metadata":{"id":"-v8Or9dGX5eq"}},{"cell_type":"code","source":"def find_classes(dir):\n    classes = os.listdir(dir)\n    classes.sort()\n    class_to_idx = {classes[i]: i for i in range(len(classes))}\n    return classes, class_to_idx\n  \nfind_classes(Config.training_dir)[1]","metadata":{"id":"dxjwPdeGX4vD","outputId":"04387019-7492-4ee2-91e0-80af20cc6af1","execution":{"iopub.status.busy":"2022-04-06T13:34:24.533626Z","iopub.execute_input":"2022-04-06T13:34:24.534161Z","iopub.status.idle":"2022-04-06T13:34:24.542781Z","shell.execute_reply.started":"2022-04-06T13:34:24.534122Z","shell.execute_reply":"2022-04-06T13:34:24.542103Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":"## Custom Dataset Class\nThis dataset generates a pair of images. 0 for geniune pair and 1 for imposter pair","metadata":{"id":"HB1XatH0wfRi"}},{"cell_type":"code","source":"class SiameseNetworkDataset(Dataset):\n    \n    def __init__(self,imageFolderDataset,transform=None,should_invert=True):\n        self.imageFolderDataset = imageFolderDataset    \n        self.transform = transform\n        self.should_invert = should_invert\n        \n    def __getitem__(self,index):\n        img0_tuple = random.choice([item for item in self.imageFolderDataset.imgs if item[1] < 29]) #Considering only genuine images for perfect pair\n        #we need to make sure approx 50% of images are in the same class\n        should_get_same_class = random.randint(0,1)\n        if should_get_same_class:\n          while True:\n            img1_tuple = random.choice(self.imageFolderDataset.imgs)\n            if img0_tuple[1]==img1_tuple[1]:\n              break\n\n        else:\n          img1_tuple = random.choice([item for item in self.imageFolderDataset.imgs if item[1] == (img0_tuple[1] + 29)]) # Considering a pair of fake + genuine of same person's signature\n\n        img0 = Image.open(img0_tuple[0])\n        img1 = Image.open(img1_tuple[0])\n        img0 = img0.convert(\"L\")\n        img1 = img1.convert(\"L\")\n        \n        if self.should_invert:\n            img0 = PIL.ImageOps.invert(img0)\n            img1 = PIL.ImageOps.invert(img1)\n\n        if self.transform is not None:\n            img0 = self.transform(img0)\n            img1 = self.transform(img1)\n        \n        return img0, img1 , torch.from_numpy(np.array([int(img1_tuple[1]!=img0_tuple[1])],dtype=np.float32))\n    \n    def __len__(self):\n        return len(self.imageFolderDataset.imgs)","metadata":{"id":"ZkesdHMTwjWC","execution":{"iopub.status.busy":"2022-04-06T13:02:28.935345Z","iopub.execute_input":"2022-04-06T13:02:28.935827Z","iopub.status.idle":"2022-04-06T13:02:28.946680Z","shell.execute_reply.started":"2022-04-06T13:02:28.935791Z","shell.execute_reply":"2022-04-06T13:02:28.945980Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Using Image Folder Dataset","metadata":{"id":"mZLIUg45wrrU"}},{"cell_type":"code","source":"folder_dataset = dset.ImageFolder(root=Config.training_dir)","metadata":{"id":"LiHUHUoAwpBy","execution":{"iopub.status.busy":"2022-04-06T13:34:31.959347Z","iopub.execute_input":"2022-04-06T13:34:31.959631Z","iopub.status.idle":"2022-04-06T13:34:31.970268Z","shell.execute_reply.started":"2022-04-06T13:34:31.959580Z","shell.execute_reply":"2022-04-06T13:34:31.969450Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset,\n                                        transform=transforms.Compose([transforms.Resize((100,100)),\n                                                                      transforms.ToTensor()\n                                                                      ])\n                                       ,should_invert=False)","metadata":{"id":"xEL6gmCywwD7","execution":{"iopub.status.busy":"2022-04-06T13:34:29.564894Z","iopub.execute_input":"2022-04-06T13:34:29.565436Z","iopub.status.idle":"2022-04-06T13:34:29.570789Z","shell.execute_reply.started":"2022-04-06T13:34:29.565397Z","shell.execute_reply":"2022-04-06T13:34:29.569998Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"## Visualising some of the data\nThe top row and the bottom row of any column is one pair. The 0s and 1s correspond to the column of the image. 1 indiciates dissimilar, and 0 indicates similar.","metadata":{"id":"pPUZH1uTw2e9"}},{"cell_type":"code","source":"vis_dataloader = DataLoader(siamese_dataset,\n                        shuffle=True,\n                        num_workers=16,\n                        batch_size=8)\ndataiter = iter(vis_dataloader)\n\n\nexample_batch = next(dataiter)\nconcatenated = torch.cat((example_batch[0],example_batch[1]),0)\nimshow(torchvision.utils.make_grid(concatenated))\nprint(example_batch[2].numpy())","metadata":{"id":"PhlPmY73wztq","outputId":"2aded951-779c-4ef7-8b16-6c380935ab6e","execution":{"iopub.status.busy":"2022-04-06T13:34:34.396249Z","iopub.execute_input":"2022-04-06T13:34:34.397062Z","iopub.status.idle":"2022-04-06T13:34:37.913529Z","shell.execute_reply.started":"2022-04-06T13:34:34.397014Z","shell.execute_reply":"2022-04-06T13:34:37.912658Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"## Neural Net Definition\nWe will use a standard convolutional neural network\n\nIts architecture might look like below,\n\n![](https://res.mdpi.com/symmetry/symmetry-10-00385/article_deploy/html/images/symmetry-10-00385-g001.png)","metadata":{"id":"E6kdnXmPxuVr"}},{"cell_type":"code","source":"class SiameseNetwork(nn.Module):\n    def __init__(self):\n        super(SiameseNetwork, self).__init__()\n        self.cnn1 = nn.Sequential(\n            nn.ReflectionPad2d(1),\n            nn.Conv2d(1, 128, kernel_size=3),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(128),\n            \n            nn.ReflectionPad2d(1),\n            nn.Conv2d(128, 64, kernel_size=3),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(64),\n            \n            nn.ReflectionPad2d(1),\n            nn.Conv2d(64, 32, kernel_size=3),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(32),\n\n            nn.ReflectionPad2d(1),\n            nn.Conv2d(32, 16, kernel_size=3),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(16),\n            \n            nn.ReflectionPad2d(1),\n            nn.Conv2d(16, 8, kernel_size=3),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(8),\n\n\n        )\n\n        self.fc1 = nn.Sequential(\n            nn.Linear(8*100*100, 500),\n            nn.ReLU(inplace=True),\n\n            nn.Linear(500, 500),\n            nn.ReLU(inplace=True),\n\n            nn.Linear(500, 5))\n\n    def forward_once(self, x):\n        output = self.cnn1(x)\n        output = output.view(output.size()[0], -1)\n        output = self.fc1(output)\n        return output\n\n    def forward(self, input1, input2):\n        output1 = self.forward_once(input1)\n        output2 = self.forward_once(input2)\n        return output1, output2","metadata":{"id":"s2ZB4D2uw7NC","execution":{"iopub.status.busy":"2022-04-06T13:02:43.353756Z","iopub.execute_input":"2022-04-06T13:02:43.354110Z","iopub.status.idle":"2022-04-06T13:02:43.413850Z","shell.execute_reply.started":"2022-04-06T13:02:43.354075Z","shell.execute_reply":"2022-04-06T13:02:43.413053Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Contrastive Loss","metadata":{"id":"EWnAhv4Ox4Rt"}},{"cell_type":"code","source":"class ContrastiveLoss(torch.nn.Module):\n    \"\"\"\n    Contrastive loss function.\n    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n    \"\"\"\n\n    def __init__(self, margin=2.0):\n        super(ContrastiveLoss, self).__init__()\n        self.margin = margin\n\n    def forward(self, output1, output2, label):\n        euclidean_distance = F.pairwise_distance(output1, output2)\n        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n\n\n        return loss_contrastive","metadata":{"id":"_PIpD6mcx1-T","execution":{"iopub.status.busy":"2022-04-06T13:02:45.271295Z","iopub.execute_input":"2022-04-06T13:02:45.271628Z","iopub.status.idle":"2022-04-06T13:02:45.286527Z","shell.execute_reply.started":"2022-04-06T13:02:45.271560Z","shell.execute_reply":"2022-04-06T13:02:45.285814Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Training Time!","metadata":{"id":"k9zIBq36x93S"}},{"cell_type":"code","source":"train_dataloader = DataLoader(siamese_dataset,\n                        shuffle=True,\n                        num_workers=8,\n                        batch_size=Config.train_batch_size)","metadata":{"id":"3pd2o_Eux7Oi","execution":{"iopub.status.busy":"2022-04-06T13:02:47.513581Z","iopub.execute_input":"2022-04-06T13:02:47.513911Z","iopub.status.idle":"2022-04-06T13:02:47.524809Z","shell.execute_reply.started":"2022-04-06T13:02:47.513875Z","shell.execute_reply":"2022-04-06T13:02:47.523269Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"net = SiameseNetwork().cuda()\ncriterion = ContrastiveLoss()\noptimizer = optim.Adam(net.parameters(),lr = 0.001)","metadata":{"id":"Gn_C1nlkyCI6","execution":{"iopub.status.busy":"2022-04-06T13:02:50.424234Z","iopub.execute_input":"2022-04-06T13:02:50.424529Z","iopub.status.idle":"2022-04-06T13:02:53.590203Z","shell.execute_reply.started":"2022-04-06T13:02:50.424495Z","shell.execute_reply":"2022-04-06T13:02:53.589428Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"counter = []\nloss_history = [] \niteration_number= 0","metadata":{"id":"32BDN703yEub","execution":{"iopub.status.busy":"2022-04-06T13:02:56.436164Z","iopub.execute_input":"2022-04-06T13:02:56.436813Z","iopub.status.idle":"2022-04-06T13:02:56.440653Z","shell.execute_reply.started":"2022-04-06T13:02:56.436770Z","shell.execute_reply":"2022-04-06T13:02:56.439871Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"for epoch in range(0,Config.train_number_epochs):\n    for i, data in enumerate(train_dataloader,0):\n        img0, img1 , label = data\n        img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n        optimizer.zero_grad()\n        output1,output2 = net(img0,img1)\n        loss_contrastive = criterion(output1,output2,label)\n        loss_contrastive.backward()\n        optimizer.step()\n        if i %10 == 0 :\n            print(\"Epoch number {}\\n Current loss {}\\n\".format(epoch,loss_contrastive.item()))\n            iteration_number +=10\n            counter.append(iteration_number)\n            loss_history.append(loss_contrastive.item())\nshow_plot(counter,loss_history)","metadata":{"id":"uGYc1HH2yGeS","outputId":"5bf0dbab-7f37-40a7-c15e-c4ebeffc61ff","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# torch.save(net,\"/content/drive/My Drive/Colab Notebooks/axis_data/processed_dataset/saved_model.pt\")\n# net = torch.load(\"/content/drive/My Drive/Colab Notebooks/axis_data/processed_dataset/saved_model.pt\")\n\n# filepath = \"/content/drive/My Drive/Colab Notebooks/axis_data/processed_dataset/final_backup_saved_model.pt\" # 0.76 threshold\n\nfilepath = \"./modified_data_loader_saved_model.pt\"\n\ntorch.save(net.state_dict(), filepath)\n\n#Later to restore:\nnet.load_state_dict(torch.load(filepath))","metadata":{"id":"bcghLptlUEWK","execution":{"iopub.status.busy":"2022-04-06T11:57:24.324736Z","iopub.execute_input":"2022-04-06T11:57:24.325049Z","iopub.status.idle":"2022-04-06T11:57:24.950716Z","shell.execute_reply.started":"2022-04-06T11:57:24.325017Z","shell.execute_reply":"2022-04-06T11:57:24.949789Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"net.load_state_dict(torch.load(\"../input/model-siamese/modified_data_loader_saved_model.pt\"))","metadata":{"execution":{"iopub.status.busy":"2022-04-06T13:03:28.596477Z","iopub.execute_input":"2022-04-06T13:03:28.597032Z","iopub.status.idle":"2022-04-06T13:03:31.294248Z","shell.execute_reply.started":"2022-04-06T13:03:28.596993Z","shell.execute_reply":"2022-04-06T13:03:31.293495Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"!ls '/content/drive/My Drive/Colab Notebooks/axis_data/processed_dataset/'","metadata":{"id":"lsExkrk8ZXz4","outputId":"f5661610-fa36-4959-83e1-cf7378b7d38c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataset loader class for inference","metadata":{"id":"gnvwj1oLn4u0"}},{"cell_type":"code","source":"class InferenceSiameseNetworkDataset(Dataset):\n    \n    def __init__(self,imageFolderDataset,transform=None,should_invert=True):\n        self.imageFolderDataset = imageFolderDataset    \n        self.transform = transform\n        self.should_invert = should_invert\n        \n    def __getitem__(self,index):\n        img0_tuple = random.choice(self.imageFolderDataset.imgs)\n        #we need to make sure approx 50% of images are in the same class\n        should_get_same_class = random.randint(0,1) \n        if should_get_same_class:\n            while True:\n                #keep looping till the same class image is found\n                img1_tuple = random.choice(self.imageFolderDataset.imgs) \n                if img0_tuple[1]==img1_tuple[1]:\n                    break\n        else:\n            while True:\n                #keep looping till a different class image is found\n                \n                img1_tuple = random.choice(self.imageFolderDataset.imgs) \n                if img0_tuple[1] !=img1_tuple[1]:\n                    break\n\n        img0 = Image.open(img0_tuple[0])\n        img1 = Image.open(img1_tuple[0])\n        img0 = img0.convert(\"L\")\n        img1 = img1.convert(\"L\")\n        \n        if self.should_invert:\n            img0 = PIL.ImageOps.invert(img0)\n            img1 = PIL.ImageOps.invert(img1)\n\n        if self.transform is not None:\n            img0 = self.transform(img0)\n            img1 = self.transform(img1)\n        \n        return img0, img1 , torch.from_numpy(np.array([int(img1_tuple[1]!=img0_tuple[1])],dtype=np.float32))\n    \n    def __len__(self):\n        return len(self.imageFolderDataset.imgs)","metadata":{"id":"M_7bPNwFKPWM","execution":{"iopub.status.busy":"2022-04-06T13:05:13.986616Z","iopub.execute_input":"2022-04-06T13:05:13.987411Z","iopub.status.idle":"2022-04-06T13:05:13.998902Z","shell.execute_reply.started":"2022-04-06T13:05:13.987270Z","shell.execute_reply":"2022-04-06T13:05:13.996580Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"output1,output2,euclidean_distance =predict_img_path(\"../input/sign-data/Dataset_Signature_Final/Dataset/dataset1/real/00100001.png\",\"../input/sign-data/Dataset_Signature_Final/Dataset/dataset1/real/00100001.png\")","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:36:35.590502Z","iopub.execute_input":"2022-04-06T14:36:35.591067Z","iopub.status.idle":"2022-04-06T14:36:35.712200Z","shell.execute_reply.started":"2022-04-06T14:36:35.591028Z","shell.execute_reply":"2022-04-06T14:36:35.711382Z"},"trusted":true},"execution_count":143,"outputs":[]},{"cell_type":"code","source":"euclidean_distance","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:35:53.785046Z","iopub.execute_input":"2022-04-06T14:35:53.785326Z","iopub.status.idle":"2022-04-06T14:35:53.793376Z","shell.execute_reply.started":"2022-04-06T14:35:53.785292Z","shell.execute_reply":"2022-04-06T14:35:53.792628Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"def predict_img_path(path1,path2):\n    img0=path1\n    img1=path2\n    img0 = Image.open(img0)\n    img1 = Image.open(img1)\n    img0 = img0.convert(\"L\")\n    img1 = img1.convert(\"L\")\n    img0_t = tr(img0)\n    img1_t = tr(img1)\n    img0_t=(img0_t.unsqueeze(0))\n    img1_t=(img1_t.unsqueeze(0))\n    output1,output2 = net(Variable(img0_t).cuda(),Variable(img1_t).cuda())\n    euclidean_distance = F.pairwise_distance(output1, output2)\n    imshow(torchvision.utils.make_grid(torch.cat((img0_t,img1_t),0)),'Dissimilarity: {:.2f}'.format(euclidean_distance.item()))\n    return output1,output2,euclidean_distance","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:36:02.771268Z","iopub.execute_input":"2022-04-06T14:36:02.771540Z","iopub.status.idle":"2022-04-06T14:36:02.781681Z","shell.execute_reply.started":"2022-04-06T14:36:02.771509Z","shell.execute_reply":"2022-04-06T14:36:02.780920Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"code","source":"output1","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:19:50.109850Z","iopub.execute_input":"2022-04-06T14:19:50.110129Z","iopub.status.idle":"2022-04-06T14:19:50.120206Z","shell.execute_reply.started":"2022-04-06T14:19:50.110097Z","shell.execute_reply":"2022-04-06T14:19:50.119267Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"euclidean_distance = F.pairwise_distance(output1, output2)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:17:58.535654Z","iopub.execute_input":"2022-04-06T14:17:58.536119Z","iopub.status.idle":"2022-04-06T14:17:58.540841Z","shell.execute_reply.started":"2022-04-06T14:17:58.536082Z","shell.execute_reply":"2022-04-06T14:17:58.539942Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"imshow(torchvision.utils.make_grid(torch.cat((img0_t,img1_t),0)),'Dissimilarity: {:.2f}'.format(euclidean_distance.item()))","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:18:54.236955Z","iopub.execute_input":"2022-04-06T14:18:54.237235Z","iopub.status.idle":"2022-04-06T14:18:54.370475Z","shell.execute_reply.started":"2022-04-06T14:18:54.237204Z","shell.execute_reply":"2022-04-06T14:18:54.369576Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"markdown","source":"## Some simple testing\n\nSubject 4 was held out from the training, and will be used to test. The Distance between each image pair denotes the degree of similarity the model found between the two images. Less means it found more similar, while higher values indicate it found them to be dissimilar.\n\nA genuine image on the left is held fixed and is compared with genuine, forged, and different signature.\n\nGenuine : 6,10\n\nForged: 1,5,7,9\n\nDifferent : 2,3,4,8","metadata":{"id":"zQWn-_mzyOyE"}},{"cell_type":"code","source":"folder_dataset_test = dset.ImageFolder(root=Config.testing_dir)\nsiamese_dataset = InferenceSiameseNetworkDataset(imageFolderDataset=folder_dataset_test,\n                                        transform=transforms.Compose([transforms.Resize((100,100)),\n                                                                      transforms.ToTensor()\n                                                                      ])\n                                       ,should_invert=False)\n\ntest_dataloader = DataLoader(siamese_dataset,num_workers=6,batch_size=1,shuffle=True)\ndataiter = iter(test_dataloader)\nx0,_,_ = next(dataiter)\n\nfor i in range(10):\n    _,x1,label2 = next(dataiter)\n    concatenated = torch.cat((x0,x1),0)\n    \n    output1,output2 = net(Variable(x0).cuda(),Variable(x1).cuda())\n    euclidean_distance = F.pairwise_distance(output1, output2)\n    imshow(torchvision.utils.make_grid(concatenated),'Dissimilarity: {:.2f}'.format(euclidean_distance.item()))\n","metadata":{"id":"ulVgJaLgyJ8U","outputId":"6c5d6c21-9101-481d-8e7a-d99f886881d1","execution":{"iopub.status.busy":"2022-04-06T13:34:51.781004Z","iopub.execute_input":"2022-04-06T13:34:51.781312Z","iopub.status.idle":"2022-04-06T13:34:54.605405Z","shell.execute_reply.started":"2022-04-06T13:34:51.781272Z","shell.execute_reply":"2022-04-06T13:34:54.604500Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"euclidean_distance","metadata":{"execution":{"iopub.status.busy":"2022-04-06T13:05:32.261284Z","iopub.execute_input":"2022-04-06T13:05:32.261567Z","iopub.status.idle":"2022-04-06T13:05:32.304753Z","shell.execute_reply.started":"2022-04-06T13:05:32.261534Z","shell.execute_reply":"2022-04-06T13:05:32.303828Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"**In conclusion, promising results have been obtained by training a relatively smaller network on only sample dataset provided by the organizers and no additional dataset or the extra dataset provided in the phase two had been used.   This proves the versatility of the Siamese Neural Network for the task of one-shot learning with relatively smaller dataset.**","metadata":{"id":"ljk2cfe6G9hM"}}]}